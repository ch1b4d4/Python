{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Programming: Bayesian Estimation Exercise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1\n",
    "# ---\n",
    "# Determine the bias of a Thumbtack \n",
    "# (A thumbtack is a short flat-headed pin, used for fastening paper to a wall or other surface.)\n",
    "# ---\n",
    "# \n",
    "\n",
    "# We shall use the excellent PyMC library. Let's install it\n",
    "# We shall avoid going into the finer details of PyMC. Excellent documentation for PyMC \n",
    "# can be found both in the PyMC docs as well as the book \"Probabilistic Programming and Bayesian methods for Hackers\" \n",
    "# by Cam Davidson-Pilon's, which can be found online at \n",
    "# http://camdavidsonpilon.github.io/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/.\n",
    "url = ('http://camdavidsonpilon.github.io/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/.')\n",
    "!pip3 install pymc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pymc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/Users/la/Documents/Python/Pvalues/Bayesian_Estimation.ipynb Cell 3'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/la/Documents/Python/Pvalues/Bayesian_Estimation.ipynb#ch0000002?line=0'>1</a>\u001b[0m \u001b[39m# For estimating theta, we cxroughly 30% of the generated values being 1, and the rest being 0).\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/la/Documents/Python/Pvalues/Bayesian_Estimation.ipynb#ch0000002?line=1'>2</a>\u001b[0m \n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/la/Documents/Python/Pvalues/Bayesian_Estimation.ipynb#ch0000002?line=2'>3</a>\u001b[0m \u001b[39m# Importing the libraries we will need\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/la/Documents/Python/Pvalues/Bayesian_Estimation.ipynb#ch0000002?line=3'>4</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpymc\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/la/Documents/Python/Pvalues/Bayesian_Estimation.ipynb#ch0000002?line=4'>5</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mscipy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mstats\u001b[39;00m \u001b[39mimport\u001b[39;00m bernoulli\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/la/Documents/Python/Pvalues/Bayesian_Estimation.ipynb#ch0000002?line=5'>6</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pymc'"
     ]
    }
   ],
   "source": [
    "# For estimating theta, we cxroughly 30% of the generated values being 1, and the rest being 0).\n",
    "\n",
    "# Importing the libraries we will need\n",
    "from pymc import *\n",
    "from scipy.stats import bernoulli\n",
    "import matplotlib.pyplot as plt\n",
    "import pymc.Matplot as plott\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We attempt to find the parameters of the posterior distribution, and we've learnt that the posterior depends on the prior, as well the data. \n",
    "# There are many choices of prior available to us, in this case we shall use the uniform prior. \n",
    "# Since we have little idea about the bias of the thumbtack, we believe it can lie anywhere between 0 and 1.\n",
    "# The PyMC model contains two variables. The first is a Uniform prior, which represents our belief \n",
    "# that the value of the parameter can be anywhere between 0 and 1. \n",
    "# The second is the Bernoulli variable, to which we provide data. The two variables are linked in a parent-child relationship, \n",
    "# the Uniform prior is the designated parent of the Bernoulli variable.\n",
    "# We use two types of PyMC variables: Stochastic (the uni_prior variable, which can take different values based on the parameter theta). \n",
    "# Deterministic (such as 'bern', whose values are decided by its parents). Finally, all the variables in the model are wrapped in a Model object.\n",
    "# For all variables where observed is not True, PyMC's simulations will tickle the value of the variable during the simulation \n",
    "# and the value (of uni_prior in our case) will start to approximate its posterior values.\n",
    "\n",
    "from pymc import *\n",
    "from scipy.stats import bernoulli\n",
    "import matplotlib.pyplot as plt\n",
    "import pymc.Matplot as plott\n",
    "\n",
    "# Samples drawn from the prior distribution show that the prior is uniformly distributed between 0 and 1 on the x axis.\n",
    "def create_model(data):\n",
    "    #create a uniform prior, the lower and upper limits of which are 0 and 1\n",
    "    uni_prior = Uniform('uni_prior', lower=0,upper=1.0 )\n",
    "    bern = Bernoulli('bern',p=uni_prior, value=data,observed=True)\n",
    "    model=Model([uni_prior,bern])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We now use a sampling method called Markov Chain Monte Carlo (hence the acronym MCMC). \n",
    "# MCMC is one of the methods used to draw samples from the posterior distribution. \n",
    "# We draw 5k samples, and draw a histogram of the samples (called traces in MCMC parlance).\n",
    "# In Bayesian statistics, the parameter theta is represented as a random variable and not a single value.\n",
    "\n",
    "sample_size=30\n",
    "\n",
    "def get_traces(sample_size):\n",
    "    data=bernoulli.rvs(0.3,size=sample_size)\n",
    "    model=create_model(data)\n",
    "    model.seed()\n",
    "    mc1 = MCMC(model)\n",
    "    mc1.sample(iter=5000,burn=1000)\n",
    "    return mc1,mc1.trace('uni_prior')[:]\n",
    "\n",
    "mc1,traces=get_traces(sample_size)\n",
    "plott.histogram(traces,\"uni_prior\")\n",
    "\n",
    "\n",
    "# We plot the posterior distribution of the parameter theta. We can see that the distribution has quite a bit of variance, \n",
    "# and the peak of the distribution (indicated by a black vertical line) \n",
    "# does not correspond to 0.3 (which is the true value of the parameter theta). \n",
    "# The peak of the distribution hill is called a point estimate in Bayesian parlance, \n",
    "# which is analogous to the \"best estimate\" if we want to represent the parameter theta as a single value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We then plot the posterior distribution for an increasing number of samples.\n",
    "num_samples=[20,50,100,500,5000]\n",
    "for i in num_samples:\n",
    "    m,traces=get_traces(i)\n",
    "    plott.histogram(traces,\"num samples = \"+str(i),datarange=(0,0.6))\n",
    "    \n",
    "# We can see that increasing the number of samples makes the distribution \"hill\" sharper, \n",
    "# which indicates its growing confidence in its estimate of the parameter theta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 2\n",
    "# ---\n",
    "# I tossed my coin 30  times, and it came up as heads  11  times. Is it biased?\n",
    "# ---\n",
    "# \n",
    "\n",
    "# Parameterized problem:\n",
    "#\n",
    "# \"I want to know  p , the probability of tossing heads. Given  n  tosses and  h  observed heads, \n",
    "# is it probable that the value of  p  is close to  0.5  , say, in the interval  [0.48,0.52] ?\"\n",
    "\n",
    "# Prior:\n",
    "# prior belief about parameter:  p∼Uniform(0,1) \n",
    "# likelihood function:  data∼Bernoulli(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the data needed for the problem.\n",
    "from random import shuffle\n",
    "total = 30\n",
    "n_heads = 11\n",
    "n_tails = total - n_heads\n",
    "tosses = [1] * n_heads + [0] * n_tails\n",
    "shuffle(tosses)\n",
    "\n",
    "# printing out data\n",
    "print(tosses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a function to plot our tosses\n",
    "def plot_coins():\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    ax.bar(list(Counter(tosses).keys()), list(Counter(tosses).values()))\n",
    "    ax.set_xticks([0, 1])\n",
    "    ax.set_xticklabels(['tails', 'heads'])\n",
    "    ax.set_ylim(0, 20)\n",
    "    ax.set_yticks(np.arange(0, 21, 5))\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting\n",
    "fig = plot_coins()\n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Context manager syntax. `coin_model` is **just** \n",
    "# a placeholder\n",
    "# \n",
    "with pm.Model() as coin_model: \n",
    "    # Distributions are PyMC3 objects.\n",
    "    # Specify prior using Uniform object.\n",
    "    p_prior = pm.Uniform('p', 0, 1)  \n",
    "    \n",
    "    # Specify likelihood using Bernoulli object.\n",
    "    like = pm.Bernoulli('likelihood', p=p_prior, \n",
    "                        observed=tosses)  \n",
    "                        # \"observed=data\" is key\n",
    "                        # for likelihood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing our model in PyMC3, hitting the MCMC Inference Button (TM)\n",
    "# \n",
    "with coin_model:\n",
    "    # don't worry about this:\n",
    "    step = pm.Metropolis()\n",
    "    \n",
    "    # focus on this, the Inference Button:\n",
    "    coin_trace = pm.sample(2000, step=step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results\n",
    "# \n",
    "pm.traceplot(coin_trace)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpreting based on posterior distributions\n",
    "# \n",
    "pm.plot_posterior(coin_trace[100:], color='#87ceeb', \n",
    "                  rope=[0.48, 0.52], point_estimate='mean', \n",
    "                  ref_val=0.5)\n",
    "plt.show()\n",
    "\n",
    "# 95% highest posterior density (HPD) encompasses the region of practical equivalence (ROPE) \n",
    "# thus we need to get more data. For more info (http://bit.ly/HPDandROPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Challenge 1\n",
    "# ---\n",
    "# I tossed my coin 50  times, and it came up as tails 29  times. Is it biased?\n",
    "# --\n",
    "# \n",
    "OUR CODE GOES HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Challenge 2\n",
    "# ---\n",
    "# Assume that we run an website for selling safari shoes and in order to bring people to our site, \n",
    "# we deploy several digital marketing campaigns. \n",
    "# These campaigns feature various ad images and captions, and are presented on a number of social networking websites. \n",
    "# We want to present the ads that are the most successful. \n",
    "# For the sake of simplicity, we can assume that the most successful campaign \n",
    "# is the one that results in the highest click-through rate: the ads that are most likely to be clicked if shown.\n",
    "# We introduce a new campaign called \"facebook-yellow-dress,\" a campaign presented to Facebook users featuring a yellow dress. \n",
    "# The ad has been presented to 10 users so far, and 7 of the users have clicked on it. \n",
    "# Determine the probability that the next user will click on the ad.\n",
    "# --\n",
    "OUR CODE GOES HERE"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
